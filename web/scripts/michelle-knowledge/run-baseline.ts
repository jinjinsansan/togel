import { dirname, resolve } from "node:path";
import { fileURLToPath } from "node:url";

import { createClient, type SupabaseClient } from "@supabase/supabase-js";
import { config } from "dotenv";

const __dirname = dirname(fileURLToPath(import.meta.url));

const envPath = resolve(__dirname, "../../.env.local");
config({ path: envPath });

process.env.NODE_ENV ||= "development";
process.env.NEXT_PUBLIC_MICHELLE_AI_ENABLED ||= "true";
process.env.NEXT_PUBLIC_SUPABASE_URL ||= process.env.SUPABASE_URL ?? "";

const getEnv = (key: string) => {
  const value = process.env[key];
  if (!value) {
    throw new Error(`Missing environment variable: ${key}`);
  }
  return value;
};

const supabase = createClient(getEnv("NEXT_PUBLIC_SUPABASE_URL"), getEnv("NEXT_PUBLIC_SUPABASE_ANON_KEY"), {
  auth: {
    autoRefreshToken: false,
    persistSession: false,
  },
});

const QUESTIONS = [
  "ææ€–ã‚’æ„Ÿã˜ã‚‹æ™‚ã¯ã©ã†ã™ã‚Œã°ã„ã„ï¼Ÿ",
];

type KnowledgeMatch = {
  id: string;
  content: string;
  metadata: Record<string, unknown> | null;
  similarity: number;
};

type MichelleDeps = {
  getMichelleAssistantId: typeof import("@/lib/michelle/openai").getMichelleAssistantId;
  getMichelleOpenAIClient: typeof import("@/lib/michelle/openai").getMichelleOpenAIClient;
  supabase: SupabaseClient;
};

type BaselineResult = {
  question: string;
  answer: string;
  matches: KnowledgeMatch[];
};

const embedText = async (deps: MichelleDeps, text: string) => {
  const normalized = text.trim();
  if (!normalized) {
    console.log("âš ï¸ Empty text, skipping embedding");
    return [] as number[];
  }

  console.log(`ğŸ”„ Generating embedding for: "${normalized.slice(0, 50)}..."`);
  const openai = deps.getMichelleOpenAIClient();
  const response = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: normalized,
  });

  const embedding = response.data[0]?.embedding ?? ([] as number[]);
  console.log(`âœ… Embedding generated: ${embedding.length} dimensions`);
  return embedding;
};

const retrieveMatches = async (deps: MichelleDeps, question: string) => {
  const embedding = await embedText(deps, question);
  if (!embedding.length) {
    return [] as KnowledgeMatch[];
  }

  console.log(`ğŸ” Calling RPC with embedding[0..2]: [${embedding.slice(0, 3).join(", ")}], threshold: 0.0`);
  
  const { data, error } = await deps.supabase.rpc("match_michelle_knowledge", {
    query_embedding: embedding,
    match_count: 8,
    similarity_threshold: 0.0,
  });

  if (error) {
    console.error("Supabase RPC error details:", JSON.stringify(error, null, 2));
    throw new Error(error.message || "match_michelle_knowledge failed");
  }

  console.log(`ğŸ“Š RPC returned ${data?.length ?? 0} results`);
  return (data ?? []) as KnowledgeMatch[];
};

const runBaselineQuery = async (deps: MichelleDeps, question: string): Promise<BaselineResult> => {
  const matches = await retrieveMatches(deps, question);
  const knowledgeContext = matches
    .map((match, index) => `[å‚è€ƒçŸ¥è­˜${index + 1} | é¡ä¼¼åº¦ ${match.similarity.toFixed(3)}]\n${match.content}`)
    .join("\n\n");

  const finalMessage = matches.length
    ? `ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‘\n${question}\n\n---\nå†…éƒ¨å‚è€ƒæƒ…å ±ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ã›ãªã„ã“ã¨ï¼‰ï¼š\nä»¥ä¸‹ã®ãƒŸã‚·ã‚§ãƒ«å¿ƒç†å­¦çŸ¥è­˜ã‚’å‚è€ƒã«ã—ã¦å›ç­”ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚\n${knowledgeContext}`
    : question;

  const openai = deps.getMichelleOpenAIClient();
  const assistantId = deps.getMichelleAssistantId();
  const betaThreads = openai.beta?.threads;

  if (!betaThreads) {
    throw new Error("OpenAI Assistants beta API is not available");
  }

  const thread = await betaThreads.create();
  await betaThreads.messages.create(thread.id, { role: "user", content: finalMessage });

  const run = await betaThreads.runs.createAndPoll(thread.id, { assistant_id: assistantId });
  if (run.status !== "completed") {
    throw new Error(`Assistant run did not complete (status: ${run.status})`);
  }

  const messages = await betaThreads.messages.list(thread.id, { order: "desc", limit: 5 });
  const assistantMessage = messages.data.find((message) => message.role === "assistant");

  if (!assistantMessage) {
    throw new Error("No assistant response found in thread");
  }

  const answer = assistantMessage.content
    .map((part) => (part.type === "text" ? part.text.value : ""))
    .join("\n")
    .trim();

  return {
    question,
    answer,
    matches,
  };
};

const main = async (deps: MichelleDeps) => {
  const results: BaselineResult[] = [];

  for (const question of QUESTIONS) {
    console.log(`\n============================`);
    console.log(`ğŸ“ è³ªå•: ${question}`);

    try {
      const result = await runBaselineQuery(deps, question);
      results.push(result);

      console.log(`ğŸ” ãƒ’ãƒƒãƒˆä»¶æ•°: ${result.matches.length}`);
      result.matches.forEach((match, index) => {
        const preview = match.content.replace(/\s+/g, " ").slice(0, 120);
        console.log(`  - [${index + 1}] é¡ä¼¼åº¦ ${match.similarity.toFixed(3)} | ${preview}${preview.length === 120 ? "â€¦" : ""}`);
      });
      console.log(`\nğŸ’¬ å¿œç­”:\n${result.answer}\n`);
    } catch (error) {
      console.error(`âŒ ã‚¨ãƒ©ãƒ¼: ${(error as Error).message}`);
    }
  }

  console.log(`\n============================`);
  console.log(`âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šå®Œäº† (åˆè¨ˆ ${results.length} ä»¶)`);
};

import("@/lib/michelle/openai")
  .then(async (openaiModule) => {
    const deps: MichelleDeps = {
      getMichelleAssistantId: openaiModule.getMichelleAssistantId,
      getMichelleOpenAIClient: openaiModule.getMichelleOpenAIClient,
      supabase,
    };

    await main(deps);
  })
  .catch((error) => {
    console.error("Baseline measurement failed", error);
    process.exit(1);
  });
